{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Facial Recognition With A Siamese Network** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Layer , Conv2D , MaxPooling2D , Dense , Flatten , Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus :\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory 'data\\positive' already exists.\n",
      "The directory 'data\\negative' already exists.\n",
      "The directory 'data\\anchor' already exists.\n"
     ]
    }
   ],
   "source": [
    "POS_PATH = os.path.join('data' , 'positive')\n",
    "NEG_PATH = os.path.join('data' , 'negative')\n",
    "ANC_PATH = os.path.join('data' , 'anchor')\n",
    "\n",
    "if not os.path.exists(POS_PATH):\n",
    "    os.makedirs(POS_PATH)\n",
    "else:\n",
    "    print(f\"The directory '{POS_PATH}' already exists.\")\n",
    "\n",
    "if not os.path.exists(NEG_PATH):\n",
    "    os.makedirs(NEG_PATH)\n",
    "else:\n",
    "    print(f\"The directory '{NEG_PATH}' already exists.\")\n",
    "\n",
    "if not os.path.exists(ANC_PATH):\n",
    "    os.makedirs(ANC_PATH)\n",
    "else:\n",
    "    print(f\"The directory '{ANC_PATH}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'lfw'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5816\\3149588820.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lfw'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lfw'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mEX_PATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lfw'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mNEW_PATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNEG_PATH\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEX_PATH\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mNEW_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'lfw'"
     ]
    }
   ],
   "source": [
    "for directory in os.listdir('lfw'):\n",
    "    for file in os.listdir(os.path.join('lfw' , directory)):\n",
    "        EX_PATH = os.path.join('lfw' , directory , file)\n",
    "        NEW_PATH = os.path.join(NEG_PATH , file)\n",
    "        os.replace(EX_PATH , NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "data\\anchor\\caebf88a-cc07-11ee-8d96-bc542f0a7ab1.jpg\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret , frame = cap.read()\n",
    "    frame = frame[120:120+250,200:200+250,:]\n",
    "    \n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        print(1)\n",
    "        img_name = os.path.join(ANC_PATH , '{}.jpg'.format(uuid.uuid1()))\n",
    "        print(img_name)\n",
    "        cv2.imwrite(img_name , frame)\n",
    "        \n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        img_name = os.path.join(POS_PATH , '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(img_name , frame)\n",
    "\n",
    "\n",
    "    cv2.imshow('Image Collection' , frame)\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(300)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(300)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    \n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img,(100,100))\n",
    "    img = img/255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data.as_numpy_iterator()\n",
    "example = samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img , validation_img , label):\n",
    "    return(preprocess(input_img) , preprocess(validation_img) , label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "twin = preprocess_twin(*example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
       " array([[[0.9843137 , 1.        , 1.        ],\n",
       "         [0.98333335, 1.        , 1.        ],\n",
       "         [0.98039216, 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.33235294, 0.28333333, 0.1872549 ],\n",
       "         [0.3360294 , 0.28112745, 0.17916666],\n",
       "         [0.34509805, 0.28235295, 0.18431373]],\n",
       " \n",
       "        [[0.98039216, 1.        , 1.        ],\n",
       "         [0.98039216, 1.        , 1.        ],\n",
       "         [0.9789216 , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.35637254, 0.31004903, 0.22181372],\n",
       "         [0.35465688, 0.3009804 , 0.2017157 ],\n",
       "         [0.3617647 , 0.3       , 0.20980392]],\n",
       " \n",
       "        [[0.9705882 , 1.        , 1.        ],\n",
       "         [0.9705882 , 1.        , 1.        ],\n",
       "         [0.96911764, 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.3602941 , 0.3139706 , 0.22573529],\n",
       "         [0.36985293, 0.3139706 , 0.22279412],\n",
       "         [0.38235295, 0.32058823, 0.23039216]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.11176471, 0.14509805, 0.16568628],\n",
       "         [0.10906862, 0.1375    , 0.14926471],\n",
       "         [0.13284314, 0.14803922, 0.16495098],\n",
       "         ...,\n",
       "         [0.22941177, 0.22720589, 0.20906863],\n",
       "         [0.25980392, 0.27720588, 0.25465685],\n",
       "         [0.3348039 , 0.3485294 , 0.32205883]],\n",
       " \n",
       "        [[0.10465686, 0.12622549, 0.1497549 ],\n",
       "         [0.10514706, 0.12696078, 0.14166667],\n",
       "         [0.11960784, 0.1392157 , 0.15465686],\n",
       "         ...,\n",
       "         [0.16446078, 0.1615196 , 0.15367647],\n",
       "         [0.18578431, 0.20245098, 0.1877451 ],\n",
       "         [0.23063725, 0.25588235, 0.2372549 ]],\n",
       " \n",
       "        [[0.09607843, 0.11568628, 0.1392157 ],\n",
       "         [0.09313726, 0.1127451 , 0.12843138],\n",
       "         [0.10171568, 0.12132353, 0.14289215],\n",
       "         ...,\n",
       "         [0.14509805, 0.13235295, 0.12156863],\n",
       "         [0.12843138, 0.14509805, 0.13039216],\n",
       "         [0.1377451 , 0.18186274, 0.16617647]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
       " array([[[0.2627451 , 0.28235295, 0.29803923],\n",
       "         [0.2637255 , 0.28137255, 0.29803923],\n",
       "         [0.27058825, 0.28235295, 0.3019608 ],\n",
       "         ...,\n",
       "         [0.8872549 , 0.89509803, 0.877451  ],\n",
       "         [0.89705884, 0.904902  , 0.8931373 ],\n",
       "         [0.9019608 , 0.9098039 , 0.8980392 ]],\n",
       " \n",
       "        [[0.26764706, 0.28921568, 0.30686274],\n",
       "         [0.26568627, 0.28529412, 0.30294117],\n",
       "         [0.2602941 , 0.2754902 , 0.29534313],\n",
       "         ...,\n",
       "         [0.90392154, 0.9117647 , 0.89411765],\n",
       "         [0.9105392 , 0.91838235, 0.90661764],\n",
       "         [0.90392154, 0.9117647 , 0.9       ]],\n",
       " \n",
       "        [[0.24215686, 0.26960784, 0.2990196 ],\n",
       "         [0.25      , 0.2754902 , 0.30490196],\n",
       "         [0.24019608, 0.26568627, 0.29509804],\n",
       "         ...,\n",
       "         [0.9098039 , 0.91764706, 0.9       ],\n",
       "         [0.9107843 , 0.91862744, 0.90686274],\n",
       "         [0.9139706 , 0.9218137 , 0.910049  ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.13235295, 0.14191176, 0.16960785],\n",
       "         [0.15906863, 0.17352942, 0.19632353],\n",
       "         [0.17205882, 0.19387256, 0.20784314],\n",
       "         ...,\n",
       "         [0.6754902 , 0.70490193, 0.65294117],\n",
       "         [0.6757353 , 0.7051471 , 0.64730394],\n",
       "         [0.67745095, 0.70686275, 0.6490196 ]],\n",
       " \n",
       "        [[0.1382353 , 0.14215687, 0.15808824],\n",
       "         [0.16617647, 0.18382353, 0.1867647 ],\n",
       "         [0.16470589, 0.2       , 0.19019608],\n",
       "         ...,\n",
       "         [0.702451  , 0.7259804 , 0.672549  ],\n",
       "         [0.69730395, 0.7230392 , 0.6637255 ],\n",
       "         [0.69411767, 0.7205882 , 0.6598039 ]],\n",
       " \n",
       "        [[0.1247549 , 0.12671569, 0.14338236],\n",
       "         [0.13995098, 0.16348039, 0.16348039],\n",
       "         [0.10465686, 0.14313726, 0.1392157 ],\n",
       "         ...,\n",
       "         [0.68921566, 0.7137255 , 0.65686274],\n",
       "         [0.68014705, 0.70759803, 0.64485294],\n",
       "         [0.69215685, 0.71960783, 0.65686274]]], dtype=float32)>,\n",
       " 1.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.take(round(len(data)*0.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.skip(round(len(data)*0.7))\n",
    "test_data = test_data.take(round(len(data)*0.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    \n",
    "    input = Input(shape=(100,100,3) , name='input_img')\n",
    "    \n",
    "    c1 = Conv2D(64,(10,10) , activation='relu')(input)\n",
    "    m1 = MaxPooling2D(64,(2,2) , padding='same')(c1)\n",
    "    \n",
    "    c2 = Conv2D(128,(7,7) , activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64,(2,2) , padding='same')(c2)\n",
    "\n",
    "    c3 = Conv2D(128,(4,4) , activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64,(2,2) , padding='same')(c3)\n",
    "    \n",
    "    c4 = Conv2D(256,(4,4) , activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096 , activation='sigmoid')(f1)\n",
    "    \n",
    "    return Model(inputs=[input] , outputs=[d1] , name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_img (InputLayer)       [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 91, 91, 64)        19264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 46, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 40, 40, 128)       401536    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 128)       262272    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 256)         524544    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              37752832  \n",
      "=================================================================\n",
      "Total params: 38,960,448\n",
      "Trainable params: 38,960,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Dist(Layer):\n",
    "    \n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "    def call(self,input_embedding,validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = L1Dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "    input_image = Input(name='input_image' , shape=(100,100,3))\n",
    "    validation_image = Input(name='validation_image' , shape=(100,100,3))\n",
    "    \n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(embedding(input_image) , embedding(validation_image))\n",
    "    \n",
    "    classifier =Dense(1 , activation='sigmoid')(distances)\n",
    "    \n",
    "    return Model(inputs=[input_image , validation_image] , outputs = classifier , name='SiameseNetwork')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "validation_image (InputLayer)   [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Functional)          (None, 4096)         38960448    input_image[0][0]                \n",
      "                                                                 validation_image[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "distance (L1Dist)               (None, 4096)         0           embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            4097        distance[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 38,964,545\n",
      "Trainable params: 38,964,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model = make_siamese_model()\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir , 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt , siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "\n",
    "    with tf.GradientTape() as tape :\n",
    "        x = batch[:2]\n",
    "        y = batch[2]\n",
    "        \n",
    "        y_hat = siamese_model(x , training=True)\n",
    "        loss = binary_cross_loss(y , y_hat)\n",
    "    \n",
    "    print(loss)\n",
    "    grad = tape.gradient(loss , siamese_model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data , epochs):\n",
    "\n",
    "    for epoch in range(epochs+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch,epochs))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        for idx , batch in enumerate(data):\n",
    "            train_step(batch)\n",
    "            progbar.update(idx+1)\n",
    "    \n",
    "    if epoch % 10 == 0 :\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 0/50\n",
      "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "26/27 [===========================>..] - ETA: 0sTensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "27/27 [==============================] - 7s 215ms/step\n",
      "\n",
      " Epoch 1/50\n",
      "27/27 [==============================] - 5s 193ms/step\n",
      "\n",
      " Epoch 2/50\n",
      "27/27 [==============================] - 5s 196ms/step\n",
      "\n",
      " Epoch 3/50\n",
      "27/27 [==============================] - 5s 197ms/step\n",
      "\n",
      " Epoch 4/50\n",
      "27/27 [==============================] - 5s 202ms/step\n",
      "\n",
      " Epoch 5/50\n",
      "27/27 [==============================] - 5s 205ms/step\n",
      "\n",
      " Epoch 6/50\n",
      "27/27 [==============================] - 5s 207ms/step\n",
      "\n",
      " Epoch 7/50\n",
      "27/27 [==============================] - 5s 205ms/step\n",
      "\n",
      " Epoch 8/50\n",
      "27/27 [==============================] - 5s 208ms/step\n",
      "\n",
      " Epoch 9/50\n",
      "27/27 [==============================] - 6s 212ms/step\n",
      "\n",
      " Epoch 10/50\n",
      "27/27 [==============================] - 6s 213ms/step\n",
      "\n",
      " Epoch 11/50\n",
      "27/27 [==============================] - 6s 216ms/step\n",
      "\n",
      " Epoch 12/50\n",
      "27/27 [==============================] - 6s 214ms/step\n",
      "\n",
      " Epoch 13/50\n",
      "27/27 [==============================] - 6s 213ms/step\n",
      "\n",
      " Epoch 14/50\n",
      "27/27 [==============================] - 6s 214ms/step\n",
      "\n",
      " Epoch 15/50\n",
      "27/27 [==============================] - 6s 216ms/step\n",
      "\n",
      " Epoch 16/50\n",
      "27/27 [==============================] - 6s 218ms/step\n",
      "\n",
      " Epoch 17/50\n",
      "27/27 [==============================] - 6s 215ms/step\n",
      "\n",
      " Epoch 18/50\n",
      "27/27 [==============================] - 6s 224ms/step\n",
      "\n",
      " Epoch 19/50\n",
      "27/27 [==============================] - 6s 218ms/step\n",
      "\n",
      " Epoch 20/50\n",
      "27/27 [==============================] - 6s 219ms/step\n",
      "\n",
      " Epoch 21/50\n",
      "27/27 [==============================] - 6s 220ms/step\n",
      "\n",
      " Epoch 22/50\n",
      "27/27 [==============================] - 6s 221ms/step\n",
      "\n",
      " Epoch 23/50\n",
      "27/27 [==============================] - 6s 221ms/step\n",
      "\n",
      " Epoch 24/50\n",
      "27/27 [==============================] - 6s 221ms/step\n",
      "\n",
      " Epoch 25/50\n",
      "27/27 [==============================] - 6s 223ms/step\n",
      "\n",
      " Epoch 26/50\n",
      "27/27 [==============================] - 6s 224ms/step\n",
      "\n",
      " Epoch 27/50\n",
      "27/27 [==============================] - 6s 225ms/step\n",
      "\n",
      " Epoch 28/50\n",
      "27/27 [==============================] - 6s 224ms/step\n",
      "\n",
      " Epoch 29/50\n",
      "27/27 [==============================] - 6s 224ms/step\n",
      "\n",
      " Epoch 30/50\n",
      "27/27 [==============================] - 6s 224ms/step\n",
      "\n",
      " Epoch 31/50\n",
      "27/27 [==============================] - 6s 224ms/step\n",
      "\n",
      " Epoch 32/50\n",
      "27/27 [==============================] - 6s 224ms/step\n",
      "\n",
      " Epoch 33/50\n",
      "27/27 [==============================] - 6s 224ms/step\n",
      "\n",
      " Epoch 34/50\n",
      "27/27 [==============================] - 6s 227ms/step\n",
      "\n",
      " Epoch 35/50\n",
      "27/27 [==============================] - 6s 226ms/step\n",
      "\n",
      " Epoch 36/50\n",
      "27/27 [==============================] - 6s 226ms/step\n",
      "\n",
      " Epoch 37/50\n",
      "27/27 [==============================] - 6s 230ms/step\n",
      "\n",
      " Epoch 38/50\n",
      "27/27 [==============================] - 6s 230ms/step\n",
      "\n",
      " Epoch 39/50\n",
      "27/27 [==============================] - 6s 230ms/step\n",
      "\n",
      " Epoch 40/50\n",
      "27/27 [==============================] - 6s 230ms/step\n",
      "\n",
      " Epoch 41/50\n",
      "27/27 [==============================] - 6s 228ms/step\n",
      "\n",
      " Epoch 42/50\n",
      "27/27 [==============================] - 6s 227ms/step\n",
      "\n",
      " Epoch 43/50\n",
      "27/27 [==============================] - 6s 226ms/step\n",
      "\n",
      " Epoch 44/50\n",
      "27/27 [==============================] - 6s 231ms/step\n",
      "\n",
      " Epoch 45/50\n",
      "27/27 [==============================] - 6s 231ms/step\n",
      "\n",
      " Epoch 46/50\n",
      "27/27 [==============================] - 6s 229ms/step\n",
      "\n",
      " Epoch 47/50\n",
      "27/27 [==============================] - 6s 229ms/step\n",
      "\n",
      " Epoch 48/50\n",
      "27/27 [==============================] - 6s 229ms/step\n",
      "\n",
      " Epoch 49/50\n",
      "27/27 [==============================] - 6s 229ms/step\n",
      "\n",
      " Epoch 50/50\n",
      "27/27 [==============================] - 6s 230ms/step\n"
     ]
    }
   ],
   "source": [
    "train(train_data,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision , Recall\n",
    "\n",
    "test_input , test_val , y_true = test_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = siamese_model.predict([test_input,test_val])\n",
    "[1 if prediction > 0.5 else 0 for prediction in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Recall()\n",
    "m.update_state(y_true , predictions)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "siamese_model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('model.h5' , custom_objects={'L1Dist' : L1Dist} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "validation_image (InputLayer)   [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Functional)          (None, 4096)         38960448    input_image[0][0]                \n",
      "                                                                 validation_image[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "l1_dist_2 (L1Dist)              (None, 4096)         0           embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            4097        l1_dist_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 38,964,545\n",
      "Trainable params: 38,964,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.2758280e-12],\n",
       "       [9.9985719e-01],\n",
       "       [9.9999511e-01],\n",
       "       [3.6980007e-12],\n",
       "       [9.9999964e-01],\n",
       "       [2.4744379e-08],\n",
       "       [9.9996805e-01],\n",
       "       [3.2490207e-05],\n",
       "       [9.9974757e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9979907e-01],\n",
       "       [9.9999964e-01],\n",
       "       [9.9999845e-01],\n",
       "       [9.9982387e-01],\n",
       "       [2.6359448e-12],\n",
       "       [7.4328088e-10]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([test_input , test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def verify(model , detection_threshold , verification_threshold):\n",
    "    \n",
    "    results = []\n",
    "    for image in os.listdir(os.path.join('application_data' , 'verification_images')):\n",
    "        input_image = preprocess(os.path.join('application_data' , 'input_image' , 'input_image.jpg'))\n",
    "        validation_image = preprocess(os.path.join('application_data' , 'verification_images' , image))\n",
    "        \n",
    "        result = model.predict(list(np.expand_dims([input_image , validation_image] , axis=1)))\n",
    "        results.append(result)\n",
    "    \n",
    "    detection = np.sum(np.array(results) > detection_threshold)\n",
    "    verification = detection / len(os.listdir(os.path.join('application_data' , 'verification_images')))\n",
    "    verified = verification > verification_threshold\n",
    "    \n",
    "    return results , verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from unittest import result\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret , frame = cap.read()\n",
    "    frame = frame[120:120+250,200:200+250,:]\n",
    "    cv2.imshow('veridication' , frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
    "        cv2.imwrite(os.path.join('application_data' , 'input_image' ,'input_image.jpg') , frame)\n",
    "        \n",
    "        results , verified = verify(model, 0.9 , 0.7)\n",
    "        print(verified)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
